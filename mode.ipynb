{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('breast-cancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a folder if it doesn't exist\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    # Counting how many diagnosis are malignant(M) and how many are benign(B)\n",
    "    diagnosis_all = list(df.shape)[0]\n",
    "    diagnosis_categories = list(df['diagnosis'].value_counts())\n",
    "\n",
    "    print(\"\\n \\t The data has {} diagnosis, {} malignant and {} benign.\".format\n",
    "          (diagnosis_all, diagnosis_categories[1], diagnosis_categories[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(df):\n",
    "    #type of classes\n",
    "    print(\"classes are\",df['diagnosis'].unique())\n",
    "    classes = Counter(df['diagnosis'])\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.bar('M',classes['M'],label='Malignant',color='r')\n",
    "    plt.bar('B',classes['B'],label='Benign',color='b')\n",
    "    plt.xlabel('diagnosis')\n",
    "    plt.ylabel('count')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(os.getcwd(),'plots','class_stats.png'), dpi=300)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_parameter(df):\n",
    "    #correlation matrix using heat map for features_mean\n",
    "    features_mean= list(df.columns[1:11])\n",
    "    corr = df[features_mean].corr() # .corr is used for find corelation\n",
    "    fig, ax =plt.subplots(figsize=(14,14))\n",
    "    sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
    "           xticklabels= features_mean, yticklabels= features_mean,\n",
    "           cmap= 'coolwarm') \n",
    "    fig.savefig(os.path.join(os.getcwd(),'plots','correlation_matrix_mean.png'), dpi=300)\n",
    "\n",
    "#observations:\n",
    "\n",
    "   # 1)the radius, parameter and area are highly correlated as expected from their relation so from these we will use\n",
    "   # anyone of them\n",
    "   # 2)compactness_mean, concavity_mean and concavepoint_mean are highly correlated so we will use compactness_mean\n",
    "   # from here\n",
    "   # 3)so selected Parameter for use is perimeter_mean, texture_mean, compactness_mean, symmetry_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(df):\n",
    "    #now split our data into train and test\n",
    "    train, test = train_test_split(df,test_size=0.2,shuffle=False)\n",
    "    # Their dimensions are\n",
    "    print(\"train data shape\",train.shape)\n",
    "    print(\"test data shape\",test.shape)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_parameter=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttdata(train,test,selected_parameter):\n",
    "    train_X = train[selected_parameter]# taking the training data input \n",
    "    train_y=train.diagnosis# This is output of our training data\n",
    "    # same we have to do for test\n",
    "    test_X= test[selected_parameter] # taking test data inputs\n",
    "    test_y =test.diagnosis   #output value of test data\n",
    "    return train_X,train_y,test_X,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_parameter(df):\n",
    "    #correlation matrix using heat map for features_mean\n",
    "    features_se= list(df.columns[11:21])\n",
    "    corr = df[features_se].corr() # .corr is used for find corelation\n",
    "    fig, ax =plt.subplots(figsize=(14,14))\n",
    "    sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
    "    xticklabels= features_se, yticklabels= features_se,cmap= 'coolwarm') \n",
    "    fig.savefig(os.path.join(os.getcwd(),'plots','correlation_matrix_se.png'), dpi=300)\n",
    "\n",
    "\n",
    "#observations:\n",
    "\n",
    "   # 1)the radius, parameter and area are highly correlated as expected from their relation so from these we will use\n",
    "   # anyone of them\n",
    "   # 2)compactness_se, concavity_se and concavepoint_se are highly correlated so we will use compactness_se\n",
    "   # from here\n",
    "   # 3)so selected Parameter for use is perimeter_se, texture_se, compactness_se, symmetry_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worst_parameter(df):\n",
    "    #correlation matrix using heat map for features_mean\n",
    "    features_worst= list(df.columns[21:31])\n",
    "    corr = df[features_worst].corr() # .corr is used for find corelation\n",
    "    fig, ax = plt.subplots(figsize=(14,14))\n",
    "    sns.heatmap(corr, cbar = True,  square = True, annot=True, fmt= '.2f',annot_kws={'size': 15},\n",
    "    xticklabels= features_worst, yticklabels= features_worst,cmap= 'coolwarm') \n",
    "    fig.savefig(os.path.join(os.getcwd(),'plots','correlation_matrix_worst.png'), dpi=300)\n",
    "\n",
    "\n",
    "\n",
    "#observations:\n",
    "\n",
    "   # 1)the radius, parameter and area are highly correlated as expected from their relation so from these we will use\n",
    "   # anyone of them\n",
    "   # 2)compactness_worst, concavity_worst and concavepoint_worst are highly correlated so we will use compactness_worst\n",
    "   # from here\n",
    "   # 3)so selected Parameter for use is perimeter_worst, texture_worst, compactness_worst, symmetry_worst"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
